{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:35:39.891279Z",
     "start_time": "2024-04-22T11:35:39.878137Z"
    }
   },
   "id": "e64fef27c8d4145f",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GestureDataset(Dataset):\n",
    "    fingers = [\n",
    "        [0, 1, 2, 3, 4],\n",
    "        [0, 5, 6, 7, 8],\n",
    "        [0, 9, 10, 11, 12],\n",
    "        [0, 13, 14, 15, 16],\n",
    "        [0, 17, 18, 19, 20]\n",
    "    ]\n",
    "\n",
    "    def __init__(self, data: np.ndarray, label: np.ndarray):\n",
    "        ## data augmentation\n",
    "\n",
    "        ## get the abs value\n",
    "        data = np.abs(data)\n",
    "        ## scale data to 0~1\n",
    "        data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "        ## add the two nearby length in each finger\n",
    "        for finger in self.fingers:\n",
    "            for i in range(len(finger) - 1):\n",
    "                dist = data[:, finger[i + 1]] - data[:, finger[i]]\n",
    "                # add a new dimension\n",
    "                dist = np.expand_dims(dist, axis=1)\n",
    "                data = np.concatenate((data, dist), axis=1)\n",
    "\n",
    "        print(data.shape)\n",
    "\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:35:39.923193Z",
     "start_time": "2024-04-22T11:35:39.908261Z"
    }
   },
   "id": "cca826430608c703",
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 41, 3)\n",
      "(50000, 41, 3)\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "## load the data\n",
    "raw_data = np.load('./dataset/full_dataset_200k.npz')\n",
    "train_data, train_label, test_data, test_label = raw_data['train_data'], raw_data['train_label'], raw_data['test_data'], \\\n",
    "    raw_data['test_label']\n",
    "\n",
    "# Create an instance of the dataset\n",
    "train_dataset = GestureDataset(train_data, train_label)\n",
    "test_dataset = GestureDataset(test_data, test_label)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "data_dim = train_dataset.data.shape[1] * train_dataset.data.shape[2]\n",
    "print(data_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:35:42.016351Z",
     "start_time": "2024-04-22T11:35:39.939714Z"
    }
   },
   "id": "fd6d5b03e8fe9b5d",
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = 1\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(data_dim, 128),  # Input layer, flattening 21x3 to 63 features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.latent_dim),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, data_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()  # Using CrossEntropyLoss for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:35:42.047552Z",
     "start_time": "2024-04-22T11:35:42.033002Z"
    }
   },
   "id": "fc82646802f5d1f2",
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [1024, 128]          15,872\n",
      "              ReLU-2                [1024, 128]               0\n",
      "            Linear-3                [1024, 256]          33,024\n",
      "              ReLU-4                [1024, 256]               0\n",
      "            Linear-5                  [1024, 1]             257\n",
      "            Linear-6                [1024, 256]             512\n",
      "              ReLU-7                [1024, 256]               0\n",
      "            Linear-8                [1024, 128]          32,896\n",
      "              ReLU-9                [1024, 128]               0\n",
      "           Linear-10                [1024, 123]          15,867\n",
      "             Tanh-11                [1024, 123]               0\n",
      "================================================================\n",
      "Total params: 98,428\n",
      "Trainable params: 98,428\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.48\n",
      "Forward/backward pass size (MB): 13.93\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 14.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## summary the model\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (data_dim,), 1024, \"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:35:42.078641Z",
     "start_time": "2024-04-22T11:35:42.064092Z"
    }
   },
   "id": "d93e53ef8e0e7ca",
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch 1/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d395cda7f934e4e82e3131ae79a8e43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 2/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05902c5e35e749c498cc85892d5b3e38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 3/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f976f97d49741a096ce12bb9a12c679"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 4/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7025ea1b63f248bb8cf5b072cd3abddc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 5/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9c2f86e25ef47e180a17d2fc0dedf0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 6/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b56654aa48cd490fb15bc17fcd181194"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 7/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1571619923944769a0af39982ecaf8a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 8/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63900fabcd274a239083183290af731c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 9/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11d23f41b543485180ec497823146c70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 10/10:   0%|          | 0/196 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cf282b1142e40cc9781eacfaab011b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Training loop with tqdm progress bar\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}')\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs = inputs.to(device)\n",
    "        inputs = inputs.view(-1, data_dim)\n",
    "\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, inputs)  # Calculate loss\n",
    "\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:36:03.894146Z",
     "start_time": "2024-04-22T11:35:42.097305Z"
    }
   },
   "id": "2e47d749336adc0a",
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1) (50000,)\n"
     ]
    }
   ],
   "source": [
    "## run the test samples through the encoder\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_labels = []\n",
    "test_latent = []\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    inputs = inputs.view(-1, data_dim)\n",
    "    outputs = model.encoder(inputs)\n",
    "    test_latent.append(outputs.cpu().detach().numpy())\n",
    "    test_labels.append(labels.cpu().detach().numpy())\n",
    "\n",
    "test_latent = np.concatenate(test_latent, axis=0)\n",
    "\n",
    "test_labels = np.concatenate(test_labels, axis=0)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "print(test_latent.shape, test_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:36:04.233171Z",
     "start_time": "2024-04-22T11:36:03.909724Z"
    }
   },
   "id": "b89977e140851e8a",
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[193], line 29\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(labels):\n\u001B[0;32m     26\u001B[0m     idx \u001B[38;5;241m=\u001B[39m test_labels \u001B[38;5;241m==\u001B[39m label\n\u001B[0;32m     28\u001B[0m     ax\u001B[38;5;241m.\u001B[39mscatter(test_latent[idx, \u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m---> 29\u001B[0m                \u001B[43mtest_latent\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m,\n\u001B[0;32m     30\u001B[0m                c\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marray(matplotlib\u001B[38;5;241m.\u001B[39mcolormaps[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtab20\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcolors[i])\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[0;32m     31\u001B[0m                label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel_map[label]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     32\u001B[0m                alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[0;32m     34\u001B[0m ax\u001B[38;5;241m.\u001B[39mlegend()\n\u001B[0;32m     35\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "\u001B[1;31mIndexError\u001B[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "## plot the latent space\n",
    "%matplotlib tk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = np.unique(test_labels)\n",
    "label_map = {\n",
    "    0: 'call',\n",
    "    1: 'dislike',\n",
    "    2: 'fist',\n",
    "    3: 'like',\n",
    "    4: 'ok',\n",
    "    5: 'one',\n",
    "    6: 'palm',\n",
    "    7: 'peace',\n",
    "    8: 'rock',\n",
    "    9: 'three',\n",
    "    10: 'three2',\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title('Latent Space')\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    idx = test_labels == label\n",
    "\n",
    "    ax.scatter(test_latent[idx, 0],\n",
    "               test_latent[idx, 1],\n",
    "               c=np.array(matplotlib.colormaps['tab20'].colors[i]).reshape(1, -1),\n",
    "               label=f\"{label} {label_map[label]}\",\n",
    "               alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:36:04.403878Z",
     "start_time": "2024-04-22T11:36:04.248747Z"
    }
   },
   "id": "6c5d6ffc72166858",
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Initialize and fit KMeans\n",
    "kmeans = KMeans(n_clusters=11, random_state=0).fit(test_latent)\n",
    "\n",
    "# Predict the cluster IDs for each data point\n",
    "cluster_ids = kmeans.predict(test_latent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:36:26.330362Z",
     "start_time": "2024-04-22T11:36:26.255117Z"
    }
   },
   "id": "9e101aea1f95c4a0",
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Colors from a colormap\n",
    "colors = matplotlib.cm.get_cmap('tab20', 11)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Latent Space with K-Means Clustering')\n",
    "\n",
    "for cluster in range(11):\n",
    "    idx = cluster_ids == cluster\n",
    "    ax.scatter(test_latent[idx, 0],\n",
    "               test_latent[idx, 1],\n",
    "               c=np.array(matplotlib.colormaps['tab20'].colors[cluster]).reshape(1, -1),\n",
    "               label=f\"Cluster {cluster}\",\n",
    "               alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:36:04.554097Z",
     "start_time": "2024-04-22T11:36:04.553099Z"
    }
   },
   "id": "f840b1b6fb5ea6d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy: 0.6876\n",
      "Confusion Matrix:\n",
      "[[   3 2120    0    0    3    2    4    0 2046  103    0]\n",
      " [   3  108 1553    0    3 1979    1    0  163  153    0]\n",
      " [   2   12    0    1   24    0    1    0   32 4012    0]\n",
      " [   7 1686    0    0    1   18    2    0 2013  112    0]\n",
      " [   9    0    0 1472    4    1   10  611   10   51 2096]\n",
      " [  20    0    0    0 3950    0    2    0   25  150    0]\n",
      " [   7    0    0 3931    3    0  104   57    9   30  196]\n",
      " [7815    3    0    1   54    0  596    0   42  158    0]\n",
      " [  13    0    0    0 3779    0    4    0   19  160    0]\n",
      " [3827    0    0    9    7    0  102    1   13   73   13]\n",
      " [  23    0    0   15   22    0 4269    0   22   42    3]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate clustering accuracy\n",
    "# We need to find the best match between cluster labels and true labels\n",
    "def clustering_accuracy(true_labels, cluster_labels):\n",
    "    # Confusion matrix between true labels and cluster labels\n",
    "    matrix = confusion_matrix(true_labels, cluster_labels)\n",
    "    # Summing the highest values in each column of the confusion matrix\n",
    "    max_matches = np.sum(np.max(matrix, axis=0))\n",
    "    accuracy = max_matches / len(true_labels)\n",
    "    return matrix, accuracy\n",
    "\n",
    "\n",
    "# Calculate and print the clustering accuracy\n",
    "matrix, accuracy = clustering_accuracy(test_labels, cluster_ids)\n",
    "print(f\"Clustering Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T11:36:29.525310Z",
     "start_time": "2024-04-22T11:36:29.510311Z"
    }
   },
   "id": "74a8e67af9680443",
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dcbd4a151c7b908a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
